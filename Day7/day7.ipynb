{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [i.strip('.\\n').split(' contain ') for i in open('day7.txt').readlines()]\n",
    "data = [[j.split(', ') for j in i] for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dictionary and do BFS for part 1\n",
    "from collections import defaultdict\n",
    "import re\n",
    "pat = re.compile('(?:[\\d+]) (.* bag)')\n",
    "tree = defaultdict(list)\n",
    "for i in data:\n",
    "    # print(i)\n",
    "    for j in i[1]:\n",
    "        if j.startswith('no'):\n",
    "            continue\n",
    "        j = re.findall(pat, j)\n",
    "\n",
    "        tree[j[0]].append(i[0][0][:-1])\n",
    "\n",
    "def bfs(bags, init='shiny gold bag'):\n",
    "    visited = []\n",
    "    queue = [init]\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        if node not in visited:\n",
    "            visited.append(node)\n",
    "            neighbors = bags[node]\n",
    "\n",
    "            for neighbor in neighbors:\n",
    "                queue.append(neighbor)\n",
    "            \n",
    "    return visited\n",
    "\n",
    "len(bfs(tree))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct inverse of part 1 and do BFS again, summing up total bags seen\n",
    "from collections import defaultdict\n",
    "import re\n",
    "pat = re.compile('([\\d+]) (.* bag)')\n",
    "tree = defaultdict(list)\n",
    "for i in data:\n",
    "    # print(i)\n",
    "    for j in i[1]:\n",
    "        if j.startswith('no'):\n",
    "            continue\n",
    "        j = re.findall(pat, j)\n",
    "\n",
    "        tree[i[0][0][:-1]].append(*j)\n",
    "\n",
    "def numbags(bags, bag):\n",
    "    loc_bags = bags.get(bag)  \n",
    "\n",
    "    if not loc_bags:\n",
    "        return 0\n",
    "    else:\n",
    "        n = 0\n",
    "        for nbags, loc_bag in loc_bags:\n",
    "            j = multadd(bags, loc_bag)\n",
    "            n += j*int(nbags) + int(nbags)\n",
    "    \n",
    "    return n\n",
    "\n",
    "numbags(tree, 'shiny gold bag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_rules(self, rule, lhs, rhs, reactants, products, return_reaction_center):\n",
    "        \"\"\"Operator mapping\"\"\"\n",
    "        rxn = Chem.rdChemReactions.ReactionFromSmarts(rule)\n",
    "        reactants = reactants.split(';')\n",
    "        cofactor_index_reactants = [i for i, r in enumerate(reactants) if r != 'Any']\n",
    "        products = products.split(';')\n",
    "        cofactor_index_products = [i for i, p in enumerate(products) if p != 'Any']\n",
    "        # if number of reactants does not match reactant template\n",
    "        if len(lhs) > reactants.count('Any'):\n",
    "            repetitive_mols = set(lhs).intersection(set(rhs))\n",
    "            while repetitive_mols:\n",
    "                lhs.remove(sorted(repetitive_mols)[0])\n",
    "                rhs.remove(sorted(repetitive_mols)[0])\n",
    "                repetitive_mols = set(lhs).intersection(set(rhs))\n",
    "        lhs_set = set()\n",
    "        for lhs_perm in itertools.permutations(lhs):\n",
    "            lhs_set.add(lhs_perm)\n",
    "        for lhs_perm in lhs_set:\n",
    "            lhs_temp = list(lhs_perm)\n",
    "            for c in cofactor_index_reactants:\n",
    "                if self.molfiles_path:\n",
    "                    lhs_temp[c:c] = [Chem.MolToSmiles(Chem.MolFromMolFile(os.path.sep.join([self.molfiles_path, self.cofactor_name_dict[reactants[c]] + '.mol'])))]\n",
    "                elif self.seed_dict:\n",
    "                    lhs_temp[c:c] = [self.seed_dict[self.cofactor_name_dict[reactants[c]]]]\n",
    "            # pruned MetaCyc\n",
    "            try:\n",
    "                lhs_tuple = tuple([Chem.MolFromSmiles(i) for i in lhs_temp])\n",
    "                outputs = rxn.RunReactants(lhs_tuple)\n",
    "            except:\n",
    "                try:\n",
    "                    lhs_tuple = tuple([Chem.MolFromSmiles(i, sanitize=False) for i in lhs_temp])\n",
    "                    outputs = rxn.RunReactants(lhs_tuple)\n",
    "                except:\n",
    "                    continue\n",
    "            # # pickaxe\n",
    "            # lhs_tuple_list = []\n",
    "            # for i in lhs_temp:\n",
    "            #     try:\n",
    "            #         temp_mol = Chem.MolFromSmiles(i)\n",
    "            #         temp_mol = AllChem.AddHs(temp_mol)\n",
    "            #         AllChem.Kekulize(temp_mol, clearAromaticFlags=True)\n",
    "            #     except:\n",
    "            #         temp_mol = Chem.MolFromSmiles(i, sanitize=False)\n",
    "            #     lhs_tuple_list.append(temp_mol)\n",
    "            # lhs_tuple = tuple(lhs_tuple_list)\n",
    "            # outputs = rxn.RunReactants(lhs_tuple)\n",
    "            for rxn_output in outputs:\n",
    "                rhs_run = [Chem.MolToSmiles(rhs_mols) for rhs_mols in rxn_output]\n",
    "                rhs_list = copy.deepcopy(rhs_run)\n",
    "                for c in cofactor_index_products:\n",
    "                    rhs_list.remove(rhs_run[c])\n",
    "                # for all tautomer possibilities of clean rhs\n",
    "                for rhs in postsanitize_smiles(rhs):\n",
    "                    rhs = list(rhs)\n",
    "                    for rhs_list in postsanitize_smiles(rhs_list):\n",
    "                        # pruned MetaCyc\n",
    "                        if sorted(list(rhs_list)) == sorted(rhs):\n",
    "                            # lhs_index = [int(np.where(np.argsort(lhs) == i)[0]) for i in np.argsort(lhs_perm)]\n",
    "                            # rhs_index = [int(np.where(np.argsort(rhs) == i)[0]) for i in np.argsort(rhs_list)]\n",
    "                            lhs_index = [lhs.index(i) for i in lhs_perm]\n",
    "                            rhs_index = [rhs.index(i) for i in rhs_list]\n",
    "                            # return atom index of reaction center\n",
    "                            if return_reaction_center:\n",
    "                                # try to append lhs reactants\n",
    "                                lhs_mols = []\n",
    "                                for l in lhs_perm:\n",
    "                                    lhs_mols.append(Chem.MolFromSmiles(l))\n",
    "                                    if not lhs_mols[-1]:\n",
    "                                        lhs_mols[-1] = Chem.MolFromSmiles(l, sanitize=False)\n",
    "                                smarts_list, _ = get_smarts(rule)\n",
    "                                smarts_list = [s for i, s in enumerate(smarts_list)\n",
    "                                               if i not in cofactor_index_reactants]\n",
    "                                # possible reaction center\n",
    "                                temp_lhs_match = [Chem.MolFromSmiles(l, sanitize=False).GetSubstructMatches(\n",
    "                                    Chem.MolFromSmarts(smarts_list[i])) for i, l in enumerate(lhs_perm)]\n",
    "                                reaction_center_set = [set(itertools.chain(*l)) for l in temp_lhs_match]\n",
    "                                lhs_all_matches = itertools.product(*temp_lhs_match)\n",
    "                                # for all possible reaction centers\n",
    "                                for lhs_match in lhs_all_matches:\n",
    "                                    # iterate over all reactants\n",
    "                                    for l_idx, match in enumerate(lhs_match):\n",
    "                                        for protect in reaction_center_set[l_idx] - set(match):\n",
    "                                            lhs_mols[l_idx].GetAtomWithIdx(protect).SetProp('_protected', '1')\n",
    "                                    # add cofactors\n",
    "                                    lhs_temp_mol = list(lhs_mols)\n",
    "                                    for c in cofactor_index_reactants:\n",
    "                                        if self.molfiles_path:\n",
    "                                            lhs_temp_mol[c:c] = [Chem.MolFromMolFile(os.path.sep.join(\n",
    "                                                [self.molfiles_path, self.cofactor_name_dict[reactants[c]] + '.mol']))]\n",
    "                                        elif self.seed_dict:\n",
    "                                            lhs_temp_mol[c:c] = [Chem.MolFromSmiles(\n",
    "                                                self.seed_dict[self.cofactor_name_dict[reactants[c]]])]\n",
    "                                    # for all possible reaction outcomes\n",
    "                                    for rhs_rxn in rxn.RunReactants(tuple(lhs_temp_mol)):\n",
    "                                        for rhs_smiles in postsanitize_smiles([Chem.MolToSmiles(r) for r in rhs_rxn]):\n",
    "                                            # found match\n",
    "                                            if tuple(r for i, r in enumerate(rhs_smiles)\n",
    "                                                     if i not in cofactor_index_products) == rhs_list:\n",
    "                                                return lhs_index, rhs_index, list(lhs_match)\n",
    "                                    # else remove protection\n",
    "                                    for l_idx, match in enumerate(lhs_match):\n",
    "                                        for deprotect in reaction_center_set[l_idx] - set(match):\n",
    "                                            lhs_mols[l_idx].GetAtomWithIdx(deprotect).ClearProp('_protected')\n",
    "                            else:\n",
    "                                return lhs_index, rhs_index"
   ]
  }
 ]
}